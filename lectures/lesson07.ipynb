{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение без учителя (Unsupervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://setosa.io/ev/principal-component-analysis/\n",
    "* https://pair-code.github.io/understanding-umap/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]]\n"
     ]
    }
   ],
   "source": [
    "print(iris.data[:3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mscatter_3d(\u001b[43mdf\u001b[49m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msepal_length\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msepal_width\u001b[39m\u001b[38;5;124m'\u001b[39m, z\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpetal_width\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m               color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "fig = px.scatter_3d(df, x='sepal_length', y='sepal_width', z='petal_width',\n",
    "              color='species')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### PCA\n",
    "- [Пошаговое описание на английском](https://www.youtube.com/watch?v=FgakZw6K1QQ)\n",
    "- [Статья на Хабре на математичном](https://habr.com/ru/post/304214/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/Yorko/mlcourse.ai/raw/05aae6e7e582c2f17eab7f3355f97d14c2dc9f19/img/pca_good_bad_direction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://neerc.ifmo.ru/wiki/images/5/5a/800px-Pca_3d_to_2d_example_v2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iris.data, iris.target\n",
    "pca = PCA (n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for component in pca.components_:\n",
    "    print(' + '.join('%.3f x %s' % (value,name) for value,name in zip(component, iris.feature_names)))\n",
    "\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.scatter(X_reduced[:,0],X_reduced[:,1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decomposition_3D(model, X, target):\n",
    "    X_reduced = model.fit_transform(X)\n",
    "    x,y,z = [X_reduced[:,i] for i in range(3)]\n",
    "    fig = px.scatter_3d(x=x, y=y, z=z,\n",
    "              color=iris.target, width=800, height=800)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "plot_decomposition_3D(pca, X, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3, random_state=10)\n",
    "plot_decomposition_3D(tsne, X, iris.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = UMAP(n_components=3, random_state=10)\n",
    "plot_decomposition_3D(umap, X, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.machinelearningmastery.ru/img/0-898077-26802.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### KMeans\n",
    "- [Пошаговое описание на английском](https://www.youtube.com/watch?v=4b5d3muPQmA)\n",
    "- https://www.naftaliharris.com/blog/visualizing-k-means-clustering/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.projectrhea.org/rhea/images/e/ef/RunyanKmeans.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_3D(model, X, true):\n",
    "    pred = model.fit_predict(X)\n",
    "    X_reduced = PCA(n_components=3).fit_transform(X)\n",
    "    x,y,z = [X_reduced[:,i] for i in range(3)]\n",
    "    score = metrics.rand_score(true, pred)\n",
    "    title = 'Score for %s: %.2f' % (model.__class__.__name__, score)\n",
    "    fig = px.scatter_3d(x=x, y=y, z=z,\n",
    "              color=pred, title=title, width=800, height=800)\n",
    "    fig.show()\n",
    "\n",
    "km = KMeans (n_clusters=3)\n",
    "plot_cluster_3D(km, X, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans (n_clusters=3)\n",
    "plot_cluster_3D(km, X, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = AgglomerativeClustering(n_clusters=3)\n",
    "plot_cluster_3D(ac, X, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBSCAN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.4, min_samples=3)\n",
    "plot_cluster_3D(dbscan, X, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Rand Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Rand_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ RI = \\frac{a+b}{a+b+c+d} = \\frac{a+b}{{n \\choose 2 }} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ {\\displaystyle {n \\choose 2}} = {\\displaystyle n(n-1)/2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{RI} = \\frac{2(a + b)}{n(n-1)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     А,Б,В,Г,Д,Е\n",
    "true=[1,1,1,2,2,3]\n",
    "pred=[1,1,2,2,3,3]\n",
    "# a: AБ\n",
    "# b: АГ, АД, АЕ, БГ, БД, БЕ, ВД, ВЕ, ГЕ\n",
    "\n",
    "def pairs_by_n(n):\n",
    "    return n * (n - 1) / 2\n",
    "\n",
    "def calc_rand(a,b,n):\n",
    "    return (a+b)/pairs_by_n(n)\n",
    "\n",
    "a=1\n",
    "b=9\n",
    "n=len(true)\n",
    "calc_rand(a,b,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.rand_score(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=[1,1,1,2,2,2,3,3,3,1]\n",
    "pred=[0,0,1,1,2,2,3,3,4,4]\n",
    "# a=\n",
    "# b=\n",
    "# n=\n",
    "# calc_rand(a,b,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.rand_score(true, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Adjusted Rand index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ ARI={\\frac {\\left.\\sum _{ij}{\\binom {n_{ij}}{2}}-\\left[\\sum _{i}{\\binom {a_{i}}{2}}\\sum _{j}{\\binom {b_{j}}{2}}\\right]\\right/{\\binom {n}{2}}}{\\left.{\\frac {1}{2}}\\left[\\sum _{i}{\\binom {a_{i}}{2}}+\\sum _{j}{\\binom {b_{j}}{2}}\\right]-\\left[\\sum _{i}{\\binom {a_{i}}{2}}\\sum _{j}{\\binom {b_{j}}{2}}\\right]\\right/{\\binom {n}{2}}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=[1,1,1,2,2,2,3,3,3]\n",
    "pred=[1,1,2,2,3,3,1,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\sum _{ij}{\\binom {n_{ij}}{2}} = {\\binom {2}{2}} + {\\binom {1}{2}} +{\\binom {0}{2}} +{\\binom {0}{2}} +{\\binom {1}{2}} +{\\binom {2}{2}} +{\\binom {2}{2}} +{\\binom {1}{2}} +{\\binom {0}{2}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_nij = pairs_by_n(2) + pairs_by_n(1) + pairs_by_n(0) + pairs_by_n(0) + pairs_by_n(1) + pairs_by_n(2) + pairs_by_n(2) + pairs_by_n(1) + pairs_by_n(0)\n",
    "sum_nij"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\sum _{i}{\\binom {a_{i}}{2}} ={\\binom {3}{2}} +{\\binom {3}{2}} +{\\binom {3}{2}}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ai = pairs_by_n(3) + pairs_by_n(3) + pairs_by_n(3)\n",
    "sum_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\sum _{j}{\\binom {b_{j}}{2}} ={\\binom {4}{2}} +{\\binom {3}{2}} +{\\binom {2}{2}}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_bj = pairs_by_n(4) + pairs_by_n(3) + pairs_by_n(2)\n",
    "sum_bj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ ARI={\\frac {\\left.\\sum _{ij}{\\binom {n_{ij}}{2}}-\\left[\\sum _{i}{\\binom {a_{i}}{2}}\\sum _{j}{\\binom {b_{j}}{2}}\\right]\\right/{\\binom {n}{2}}}{\\left.{\\frac {1}{2}}\\left[\\sum _{i}{\\binom {a_{i}}{2}}+\\sum _{j}{\\binom {b_{j}}{2}}\\right]-\\left[\\sum _{i}{\\binom {a_{i}}{2}}\\sum _{j}{\\binom {b_{j}}{2}}\\right]\\right/{\\binom {n}{2}}}} = \\frac {3 - [9 \\times 10] / {\\binom {n}{2}}}{\\frac {1}{2}[9 + 10]- [9 \\times 10] / {\\binom {n}{2}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARI = (sum_nij - (sum_ai * sum_bj) / pairs_by_n(len(pred))) / ((1/2)*(sum_ai+sum_bj) - (sum_ai * sum_bj)/pairs_by_n(len(pred)))\n",
    "ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.adjusted_rand_score(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Adjusted Mutual Information\n",
    "https://en.wikipedia.org/wiki/Adjusted_mutual_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ AMI(U,V)={\\frac  {MI(U,V)-E\\{MI(U,V)\\}}{\\max {\\{H(U),H(V)\\}}-E\\{MI(U,V)\\}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.adjusted_mutual_info_score(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Homogeneity, completeness, V-measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ h = 1 - \\frac{H(C\\mid K)}{H(C)}, c = 1 - \\frac{H(K\\mid C)}{H(K)}, $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.homogeneity_score(true,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.completeness_score(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ v = 2\\frac{hc}{h+c} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.v_measure_score(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Силуэт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ s = \\frac{b - a}{\\max(a, b)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=3)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(X_reduced)\n",
    "metrics.silhouette_score(X_reduced, labels=model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=3)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(X_reduced)\n",
    "metrics.silhouette_score(X_reduced, labels=model.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots (2, 5, figsize = (10,7))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    im = X[i].reshape(1,-1)\n",
    "    ax.imshow(im.reshape((8,8)), cmap='binary')\n",
    "    ax.text(0.95,0.95, y[i])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(X,y):\n",
    "    plt.figure(figsize = (10,7))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.get_cmap('nipy_spectral', 10))\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "decompositions = [\n",
    "    PCA(n_components=2),\n",
    "    TSNE(n_components=2),\n",
    "    UMAP(n_components=2)\n",
    "]\n",
    "\n",
    "for decomposition in decompositions:\n",
    "    X_reduced = decomposition.fit_transform(X)\n",
    "    print(decomposition.__class__.__name__)\n",
    "    plot_digits(X_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = TSNE(n_components=2).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 7\n",
    "plt.figure(figsize=(4,2))\n",
    "plt.imshow(X[number].reshape(8,8))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show\n",
    "\n",
    "fig, axes = plt.subplots (8, 8, figsize = (10,7))\n",
    "fig.subplots_adjust(hspace=0.1,wspace=0.1)\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    pca = PCA(i+1).fit(X)\n",
    "    im = pca.inverse_transform(pca.transform(X[number].reshape(1,-1)))\n",
    "    ax.imshow(im.reshape(8,8), cmap='binary')\n",
    "    ax.text(0.95,0.95, i+1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(0.9)\n",
    "X_pca = pca.fit_transform(X)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "silhouette = []\n",
    "rng = range(2,20)\n",
    "for k in rng:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=17)\n",
    "    kmeans.fit(X)\n",
    "    inertia.append(np.sqrt(kmeans.inertia_))\n",
    "    score = metrics.silhouette_score(X, kmeans.labels_)\n",
    "    silhouette.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rng, inertia, marker='s')\n",
    "plt.title('Elbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rng, silhouette, marker='s')\n",
    "plt.title('Silhouette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = KMeans(n_clusters=10).fit_predict(X_reduced)\n",
    "print(metrics.adjusted_rand_score(y,pred))\n",
    "plot_digits(X_reduced, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = AgglomerativeClustering(n_clusters=10).fit_predict(X_reduced)\n",
    "print(metrics.adjusted_rand_score(y,pred))\n",
    "plot_digits(X_reduced, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "linkage_ = linkage(X, method='ward')\n",
    "dendrogram_ = dendrogram(linkage_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette = []\n",
    "rng = range(2,20)\n",
    "\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "best_epsilon=0\n",
    "for eps in rng:\n",
    "    dbscan = DBSCAN(eps=eps)\n",
    "    dbscan.fit(X_reduced)\n",
    "    labels=dbscan.labels_\n",
    "    uniq_labels = np.unique(labels)\n",
    "    n_clusters = len(uniq_labels[uniq_labels != -1])\n",
    "    if n_clusters > 1:\n",
    "        score = metrics.silhouette_score(X_reduced, labels)\n",
    "    else:\n",
    "        score = 0\n",
    "    silhouette.append(score)\n",
    "    if score>=np.max(silhouette):\n",
    "        best_epsilon=eps\n",
    "\n",
    "print('Best epsilon = %.2f, silhouette = %.2f' % (best_epsilon, np.max(silhouette)))\n",
    "plt.plot(rng, silhouette, marker='s')\n",
    "plt.title('Silhouette')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=best_epsilon)\n",
    "pred = dbscan.fit_predict(X_reduced)\n",
    "print(metrics.adjusted_rand_score(y,pred))\n",
    "plot_digits(X_reduced, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🛠 Сократить число признаков данных клиентов банка до 3 признаков (предварительно нормализовав данные) с помощью PCA или t-SNE, сделать кластеризацию без учёта целевого признака Geography на 3 кластера. Визуально отобразить данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/bank.csv')\n",
    "X,y= df.drop(columns = ['Geography']), df['Geography']\n",
    "df.head()\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🛠 Найти аномальных клиентов среди всех данных с помощью DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
